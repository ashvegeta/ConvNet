{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv(arr,filt,stride,pad_width,pad_value=0):\n",
    "    width = arr.shape[0]\n",
    "    height = arr.shape[1]\n",
    "    filt_size = filt.shape[0]\n",
    "    \n",
    "    row = col = 0\n",
    "    \n",
    "    if(len(arr.shape) == 2):\n",
    "        arr = arr.reshape(arr.shape[0],arr.shape[1],1)\n",
    "    if(len(filt.shape) == 2):\n",
    "        filt = filt.reshape(filt.shape[0],filt.shape[1],1)\n",
    "   \n",
    "    assert(filt.shape[2]==arr.shape[2]) , \"different no of channels : \" + str(filt.shape[2]) + \" , \" + str(arr.shape[2])\n",
    "    \n",
    "    \n",
    "    #padding\n",
    "    arr = np.pad(arr,((pad_width,pad_width),(pad_width,pad_width),(0,0)),'constant',constant_values=(pad_value,pad_value))\n",
    "\n",
    "    \n",
    "    # determine the size of the array obtained after convolution\n",
    "    new_width = np.int(((width + (2*pad_width) - filt_size)/stride) + 1)\n",
    "    new_height = np.int(((height + (2*pad_width) - filt_size)/stride) + 1)\n",
    "    new_arr = np.zeros(( new_width, new_height))\n",
    "\n",
    "    # perform the convolution operation \n",
    "    for i in range(0,width,stride):\n",
    "        col = 0\n",
    "        for j in range(0,height,stride):\n",
    "            conv = arr[i:i+filt_size,j:j+filt_size,:]\n",
    "            if(conv.shape == filt.shape):\n",
    "                conv = conv * filt\n",
    "                conv = conv.reshape(conv.shape[0]*conv.shape[1]*conv.shape[2])\n",
    "                new_arr[row][col] = np.sum(conv)\n",
    "                col = (col+1)%new_height\n",
    "\n",
    "        row+=1\n",
    "        \n",
    "\n",
    "    return new_arr\n",
    "\n",
    "\n",
    "def Pool(arr,filt_size,method,stride):\n",
    "    width = arr.shape[0]\n",
    "    height = arr.shape[1]\n",
    "    row = col = 0\n",
    "    \n",
    "    if(len(arr.shape) == 2):\n",
    "        arr = arr.reshape(arr.shape[0],arr.shape[1],1)\n",
    "    \n",
    "    # determine the size of the array obtained after convolution\n",
    "    new_width = np.int(((width - filt_size)/stride) + 1)\n",
    "    new_height = np.int(((height - filt_size)/stride) + 1)\n",
    "    new_arr = np.zeros(( new_width, new_height , arr.shape[2]))\n",
    "\n",
    "    # perform max pooling\n",
    "    \n",
    "    for ch in range(arr.shape[2]):\n",
    "        row = 0\n",
    "        for i in range(0,width,stride):\n",
    "            col = 0\n",
    "            for j in range(0,height,stride):\n",
    "                conv = arr[i:i+filt_size,j:j+filt_size,ch]\n",
    "            \n",
    "                if(conv.shape[:2] == (filt_size,filt_size)):\n",
    "                \n",
    "                    if(method ==\"max\"):\n",
    "                        pool = np.max(conv)\n",
    "                    elif(method ==\"mean\"):\n",
    "                        pool = np.mean(conv)\n",
    "                        \n",
    "                    new_arr[row , col , ch] = pool\n",
    "                    col = (col+1)%new_height\n",
    "\n",
    "            row+=1\n",
    "            \n",
    "    if(new_arr.shape[2]==1):\n",
    "        new_arr = new_arr.reshape(new_arr.shape[0],new_arr.shape[1])\n",
    "        \n",
    "\n",
    "    return new_arr\n",
    "\n",
    "\n",
    "def forward(layer_info,X):\n",
    "    \n",
    "    if(len(X.shape) == 3):\n",
    "        X = X.reshape(1,X.shape[0],X.shape[1],X.shape[2])\n",
    "    \n",
    "    if(len(X.shape) == 2):\n",
    "        X = X.reshape(1,X.shape[0],X.shape[1])\n",
    "        \n",
    "        \n",
    "    array = X\n",
    "    cache = []\n",
    "    \n",
    "    for layer , info in layer_info.items():\n",
    "        \n",
    "        cache.append(array)\n",
    "        \n",
    "        if(info['layer'] == \"Conv\"):\n",
    "            if(len(info['filters'].shape) == 3):\n",
    "                info['filters'] = info['filters'].reshape(1,info['filters'].shape[0],info['filters'].shape[1],info['filters'].shape[2])\n",
    "            \n",
    "            elif(len(info['filters'].shape) == 2):\n",
    "                info['filters'] = info['filters'].reshape(1,info['filters'].shape[0],info['filters'].shape[1])\n",
    " \n",
    "            array = np.array([np.array([Conv(arr,k,stride=info['stride'],pad_width=info['pad'],pad_value=info['pad value']).T for k in info['filters']]).T for arr in array]) + info['bias']\n",
    "        \n",
    "        elif(info['layer'] == \"Pool\"):\n",
    "            array = np.array([Pool(arr,filt_size=info['filt size'],method = info[\"method\"],stride=info['stride']) for arr in array])\n",
    "            \n",
    "    return array , cache\n",
    "\n",
    "\n",
    "def backward(dZ , layer_info , cache , l_rate):\n",
    "    keys = list(reversed(list(layer_info.keys())))\n",
    "    cache = list(reversed(cache))\n",
    "    \n",
    "    for key , A in zip(keys , cache):\n",
    "        \n",
    "        dA = np.zeros(A.shape)\n",
    "        \n",
    "        if(layer_info[key]['layer'] == 'Conv'):\n",
    "            \n",
    "            # get info of hyperparameters\n",
    "            pad_width ,pad_value ,stride = (layer_info[key]['pad'] , layer_info[key]['pad value'] , layer_info[key]['stride'])\n",
    "                \n",
    "\n",
    "            W = layer_info[key]['filters']\n",
    "            dW = np.zeros(layer_info[key]['filters'].shape)\n",
    "            filt_size = W.shape[1]\n",
    "\n",
    "            # pad both X and dX and store them in new set of variables\n",
    "            A_pad =  np.pad(A,((0,0),(pad_width,pad_width),(pad_width,pad_width),(0,0)),'constant',constant_values=0)\n",
    "            dA_pad = np.pad(dA,((0,0),(pad_width,pad_width),(pad_width,pad_width),(0,0)),'constant',constant_values=0)\n",
    "\n",
    "            (m , height , width , ch) = dZ.shape\n",
    "\n",
    "            #loop over samples , height and width of each image\n",
    "            for i in range(m):\n",
    "                for h in range(0,height,stride):\n",
    "                    for w in range(0,width,stride):\n",
    "\n",
    "                        # slice the array needed for convolution \n",
    "                        sliced = A_pad[i ,h:h+filt_size , w:w+filt_size, :]\n",
    "\n",
    "                        #calculate the derivatives dW and dA\n",
    "                        dW+= sliced * np.sum(dZ[i,h,w,:])\n",
    "                        dA_pad[i ,h:h+filt_size , w:w+filt_size, :]+= np.sum(W[:,:,:,:] * np.sum(dZ[i,h,w,:]),axis=0)\n",
    "\n",
    "                # once dx_pad is calculated , assign only the unpadded part to the derivative dX\n",
    "                dA[i,:,:,:] = dA_pad[i , pad_width:-pad_width, pad_width:-pad_width, :]\n",
    "\n",
    "            db = dZ.sum(axis=(0,1,2))\n",
    "            \n",
    "            layer_info[key]['filters'] -= (l_rate / m) * dW\n",
    "            layer_info[key]['bias'] -= (l_rate / m) * db\n",
    "            \n",
    "            dZ = dA\n",
    "            \n",
    "        \n",
    "        elif(layer_info[key]['layer'] == 'Pool'):\n",
    "            \n",
    "            # get info of hyperparameters\n",
    "            filt_size , stride , method = (layer_info[key]['filt size'] , layer_info[key]['stride'] , layer_info[key]['method'])\n",
    "            \n",
    "            # get dimensions of previous layer's derivatives\n",
    "            (m , height , width , ch) = dZ.shape\n",
    "            \n",
    "            for i in range(m):\n",
    "                for h in range(0,height,stride):\n",
    "                    for w in range(0,width,stride):\n",
    "                        \n",
    "                        # do backward pass for max pooling\n",
    "                        if(method == 'max'):\n",
    "                            # slice the array needed for convolution\n",
    "                            sliced = A[i ,h:h+filt_size , w:w+filt_size, :]\n",
    "                            \n",
    "                            #create a mask for the sliced array\n",
    "                            mask = (sliced == np.max(sliced))\n",
    "                            \n",
    "                            dA[i ,h:h+filt_size , w:w+filt_size, :] += mask * dA[i, h, w,:].max()\n",
    "                            \n",
    "                            \n",
    "                        #do backward pass for mean pooling\n",
    "                        elif(method == 'mean'):\n",
    "                            # slice the array needed for convolution\n",
    "                            sliced = dA[i,h,w,:]\n",
    "                            \n",
    "                            # obtain the distributed value for the sliced array\n",
    "                            shape = (filt_size , filt_size)\n",
    "                            average = sliced / (h * w)\n",
    "                            dis_value = np.ones(shape) * average \n",
    "                            \n",
    "                            dA[i ,h:h+filt_size , w:w+filt_size, :] += dis_value\n",
    "                            \n",
    "            dZ = dA \n",
    "            \n",
    "    return layer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "layer_info = {\n",
    "    \n",
    "    \"l1\" : {\n",
    "        \"layer\" : \"Conv\" ,\n",
    "        \"pad\" : 1 ,\n",
    "        \"pad value\" : 0 ,\n",
    "        \"filters\" : np.random.rand(10,3,3,3) , #(no of samples , height , width , channels) , min input to be given -> (height , width)\n",
    "        \"bias\" : np.random.rand(1,1,1,10) ,\n",
    "        \"stride\" : 2\n",
    "           }  , \n",
    "    \n",
    "    \"l2\" : {\n",
    "    \n",
    "        \"layer\" : \"Pool\" ,\n",
    "        \"filt size\" : 3 ,\n",
    "        \"stride\" : 1 , \n",
    "        \"method\" : \"max\"   #mention the method to pool i.e \"max\" or \"mean\" pooling \n",
    "           }\n",
    "    \n",
    "}\n",
    "\n",
    "X = np.random.randn(40,10,10,3)\n",
    "\n",
    "output,cache = forward(layer_info , X)  #(no of samples , height , width , channels) , min input to be given -> (height , width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 3, 3, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "y_true = np.random.randn(output.shape[0],output.shape[1],output.shape[2],output.shape[3])\n",
    "\n",
    "dZ = y_true - output\n",
    "\n",
    "layer_info_mod = backward(dZ ,layer_info , cache , 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
